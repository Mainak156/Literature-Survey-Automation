# ğŸ“˜ Literature Survey Automation

Live App: https://literature-survey-automation-lifemadeeasier-mainaksen.streamlit.app/

An AI-powered literature survey automation tool that accepts research paper DOIs and automatically generates a structured Excel literature review. The tool combines CrossRef, Semantic Scholar, full-paper PDF analysis (when open access), section-aware text extraction, and Groq LLMs (LLaMA 3.1) behind an interactive Streamlit web interface.

---

## ğŸš€ Key Features

- ğŸ“Œ DOI-based paper input
- ğŸ“š Metadata extraction via CrossRef
- ğŸ§  Abstract, methods, datasets, and TLDR via Semantic Scholar
- ğŸ“„ Full PDF download and analysis (if open access)
- âœ‚ï¸ Section-aware text extraction (identifies Methods, Results, Datasets, etc.)
- ğŸ¤– AI-powered analysis using Groq (LLaMA 3.1)
- ğŸ“Š Automatic Excel literature review generation
- ğŸŒ Interactive Streamlit UI with download-ready output

---

## ğŸ“Š Output Format

The generated Excel file contains the following columns:

- Serial No.
- Title
- Author & Year
- DOI
- Problem Addressed
- Method Used
- Dataset
- Key Findings
- Limitations

---

## ğŸ” Processing Pipeline

DOI Input  
â†“  
CrossRef (Metadata)  
â†“  
Semantic Scholar (Abstract, Methods, Datasets, TLDR)  
â†“  
PDF Download (if available)  
â†“  
Section-aware Text Extraction  
â†“  
Groq LLM (AI Analysis)  
â†“  
Excel Output  
â†“  
Streamlit UI

---

## ğŸ“ Project Structure

Literature-Survey-Automation/
â”‚
â”œâ”€â”€ app.py                     # Streamlit application
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ input/
â”‚   â””â”€â”€ dois.txt
â”œâ”€â”€ output/
â”‚   â””â”€â”€ literature_review.xlsx
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ metadata_service.py
â”‚   â”œâ”€â”€ semantic_service.py
â”‚   â”œâ”€â”€ pdf_service.py
â”‚   â”œâ”€â”€ text_extractor.py
â”‚   â””â”€â”€ llm_analyzer.py
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ excel_writer.py
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

---

## ğŸ›  Installation

1. Clone the repository
```bash
git clone https://github.com/Mainak156/Literature-Survey-Automation.git
cd Literature-Survey-Automation
```

2. Create and activate a virtual environment
```bash
python -m venv .venv
# Windows
.venv\Scripts\activate
# Linux / macOS
source .venv/bin/activate
```

3. Install dependencies
```bash
pip install -r requirements.txt
```

---

## ğŸ” Environment Configuration

Create a `.env` file (for local development) or add secrets in Streamlit Community Cloud.

Local (.env)
```env
GROQ_API_KEY="your_groq_api_key_here"
```

Streamlit Cloud (Secrets)
- Key: `GROQ_API_KEY`
- Value: `your_groq_api_key_here`

The application expects the Groq API key to call the LLM for analysis. Other service calls (CrossRef, Semantic Scholar, PDF sources) use public APIs or direct downloads.

---

## â–¶ï¸ Run Locally

```bash
streamlit run app.py
```

The app will be available at: http://localhost:8501

---

## ğŸŒ Deployment (Streamlit Community Cloud)

1. Push the repository to GitHub
2. Visit https://share.streamlit.io
3. Click "New App"
4. Select:
   - Repository: `Literature-Survey-Automation`
   - Branch: `main`
   - Main file: `app.py`
5. Set Python version = 3.10
6. Add `GROQ_API_KEY` in Secrets
7. Click Deploy

---

## ğŸ§ª Ethical Design Principles

- Avoid hallucination: do not invent missing details.
- Fields are filled only if explicitly available from sources.
- Missing or unavailable data is represented as `N/A`.
- Review and survey papers are treated appropriately (dataset/limitations might be N/A).
- Section-aware analysis improves transparency and traceability of extracted claims.

---

## âš ï¸ Known Limitations

- Closed-access PDFs cannot be parsed or analyzed (only open-access PDFs are downloaded/analyzed).
- Some papers use non-standard section headings; section-aware extraction may miss content.
- Dataset and limitations fields may remain `N/A` for review/survey/editorial papers â€” this is expected and academically correct.
- Quality of LLM analysis depends on the Groq model and the quality/availability of extracted text.

---

## ğŸ“ Use Cases

- Systematic Literature Reviews (SLR)
- Academic projects (M.Tech / MS / PhD)
- Conference or viva demonstrations
- Research automation workflows
- Rapid survey creation for proposals and related-work sections

---

## ğŸ”¬ Example Workflow

1. Add DOIs (one per line) to `input/dois.txt` or paste into the Streamlit input.
2. Run the app and start processing.
3. Let the pipeline fetch metadata, pull abstracts and methods, download PDFs (if available), extract sectioned text, and run LLM analysis.
4. Download the generated `literature_review.xlsx` from the UI.

---

## ğŸ‘¤ Author

Mainak Sen  
GitHub: https://github.com/Mainak156

---

## ğŸ“„ License

This project is released under the MIT License. See the LICENSE file for details.

---

## â­ Contributing & Feedback

Contributions, issues, suggestions, and stars are welcome. If you find the project useful, please consider starring the repository.

If you want to contribute:
- Open an issue to discuss major changes
- Send a PR with a clear description and tests where appropriate

---

## ğŸ™ Acknowledgements

- CrossRef and Semantic Scholar for metadata and abstract/method retrieval
- Groq LLM (LLaMA 3.1) for AI-driven analysis
- Streamlit for powering the interactive UI
